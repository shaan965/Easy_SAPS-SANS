q()
my_df <- read.csv("biking.csv")
my_df <- read.csv("biking.csv")
#Reading the data
dat <- read.csv("Rec System Class Algorithms.csv")
setwd("C:/Users/safwa/OneDrive/Documents/EASY-SAPS-SANS/Model_testing")
# load the package
library(stats4)
library(lattice)
library(mirt)
library(shiny)
library(readxl)
library(catR)
library(writexl)
library(shiny)
library(shinyBS)
library(shinyjs)
library(shinydashboard)
library(DT)
library(readxl)
library(ggplot2)
# load the data
questions <- read.csv("Questions.csv") # Load the SAPS question CSV file
questions2 <- read.csv("Questions2.csv") # Load the SANS question CSV file
load("sapsCoef.Rdata") # Load the SAPS coefficients
load("sapsResultGRM.Rdata") # Load the SAPS GRM results
load("sansCoef.Rdata") # Load the SANS coefficients
load("sansResultGRM.Rdata") # Load the SANS GRM results
answers <- read.csv("SAPS_answer.csv")
print(head(answers))
answers2 <- read.csv("SANS_answer.csv")
# Load the SAPS data
saps_questions <- read.csv("Questions.csv")
saps_answers <- read.csv("SAPS_answer.csv")
# Combine SAPS questions and answers
saps_data <- cbind(questions[, 1:3], saps_answers)
colnames(saps_data)[4:ncol(saps_data)] <- paste0("Q", 1:ncol(saps_answers))
# Load the SANS data
sans_questions <- read.csv("Questions2.csv")
View(saps_answers)
View(saps_answers)
View(answers)
answers <- read.csv("SAPS_answer.csv")
answers2 <- read.csv("SANS_answer.csv")
# Data spliting and training
set.seed(123) # for reproducibility
# Split SAPS responses into training and validation
set.seed(123)
saps_train_indices <- sample(1:nrow(answers), 0.8 * nrow(answers))
saps_train_responses <- answers[saps_train_indices, -1]  # Exclude the first column (SL. no)
saps_val_responses <- answers[-saps_train_indices, -1]
# Split SANS responses into training and validation
sans_train_indices <- sample(1:nrow(answers2), 0.8 * nrow(answers2))
sans_train_responses <- answers2[sans_train_indices, -1]
sans_val_responses <- answers2[-sans_train_indices, -1]
#Training Model on training Data
#Training Model on training Data
# Apply the function to SAPS training data
saps_trainResults <- lapply(saps_train_responses, calculate_scores, coef=sapsCoef, resultGRM=sapsResultGRM)
# load the package
library(stats4)
library(lattice)
library(mirt)
library(shiny)
library(readxl)
library(catR)
library(writexl)
library(shiny)
library(shinyBS)
library(shinyjs)
library(shinydashboard)
library(DT)
library(readxl)
library(ggplot2)
# load the data
questions <- read.csv("Questions.csv") # Load the SAPS question CSV file
questions2 <- read.csv("Questions2.csv") # Load the SANS question CSV file
load("sapsCoef.Rdata") # Load the SAPS coefficients
load("sapsResultGRM.Rdata") # Load the SAPS GRM results
load("sansCoef.Rdata") # Load the SANS coefficients
load("sansResultGRM.Rdata") # Load the SANS GRM results
answers <- read.csv("SAPS_answer.csv")
answers <- answers[, -1]  # Remove the "SL. no" column
print(head(answers))
answers2 <- read.csv("SANS_answer.csv")
answers2 <- answers2[, -1]  # Remove the "SL. no" column
# Data splitting and training
set.seed(123) # for reproducibility
# Split SAPS responses into training and validation
saps_train_indices <- sample(1:nrow(answers), 0.8 * nrow(answers))
saps_train_responses <- answers[saps_train_indices, ]
saps_val_responses <- answers[-saps_train_indices, ]
# Split SANS responses into training and validation
sans_train_indices <- sample(1:nrow(answers2), 0.8 * nrow(answers2))
sans_train_responses <- answers2[sans_train_indices, ]
sans_val_responses <- answers2[-sans_train_indices, ]
calculate_scores <- function(responses, coef, resultGRM, model="GRM", threshold=0.39) {
x <- as.numeric(responses)
theta <- thetaEst(coef, x, model = model, range = c(-6, 6), method = "BM")
error <- semTheta(theta, coef, x, range = c(-6, 6), model = model, method = "BM")
stop <- list(rule = "precision", thr = threshold)
checkstop <- checkStopRule(theta, error, length(x), coef, model = model, stop=stop)
Theta <- matrix(seq(-6, 6, 0.001))
tscore <- cbind(Theta, expected.test(resultGRM, Theta))
total_score <- tscore[findInterval(theta, tscore[, 1]), 2]
lower_ci <- theta - error
upper_ci <- theta + error
lower_score <- tscore[findInterval(round(lower_ci, digits = 2), tscore[, 1]), 2]
upper_score <- tscore[findInterval(round(upper_ci, digits = 2), tscore[, 1]), 2]
list(theta = theta, total_score = total_score, lower_score = lower_score, upper_score = upper_score)
}
#Training Model on training Data
# Apply the function to SAPS training data
saps_trainResults <- lapply(saps_train_responses, calculate_scores, coef=sapsCoef, resultGRM=sapsResultGRM)
# Apply the function to SANS training data
sans_trainResults <- lapply(sans_train_responses, calculate_scores, coef=sansCoef, resultGRM=sansResultGRM)
calculate_scores <- function(responses, coef, resultGRM, model="GRM", threshold=0.39) {
# Convert responses to a numeric vector
x <- as.numeric(unlist(responses))
theta <- thetaEst(coef, x, model = model, range = c(-6, 6), method = "BM")
error <- semTheta(theta, coef, x, range = c(-6, 6), model = model, method = "BM")
stop <- list(rule = "precision", thr = threshold)
checkstop <- checkStopRule(theta, error, length(x), coef, model = model, stop=stop)
Theta <- matrix(seq(-6, 6, 0.001))
tscore <- cbind(Theta, expected.test(resultGRM, Theta))
total_score <- tscore[findInterval(theta, tscore[, 1]), 2]
lower_ci <- theta - error
upper_ci <- theta + error
lower_score <- tscore[findInterval(round(lower_ci, digits = 2), tscore[, 1]), 2]
upper_score <- tscore[findInterval(round(upper_ci, digits = 2), tscore[, 1]), 2]
list(theta = theta, total_score = total_score, lower_score = lower_score, upper_score = upper_score)
}
#Training Model on training Data
# Apply the function to SAPS training data
saps_trainResults <- lapply(saps_train_responses, calculate_scores, coef=sapsCoef, resultGRM=sapsResultGRM)
calculate_scores <- function(responses, coef, resultGRM, model="GRM", threshold=0.39) {
# Convert responses to a numeric vector
x <- as.numeric(unlist(responses))
theta <- thetaEst(coef, x, model = model, range = c(-6, 6), method = "BM")
error <- semTheta(theta, coef, x, range = c(-6, 6), model = model, method = "BM")
stop <- list(rule = "precision", thr = threshold)
checkstop <- checkStopRule(theta, error, length(x), coef, model = model, stop=stop)
Theta <- matrix(seq(-6, 6, 0.001))
tscore <- cbind(Theta, expected.test(resultGRM, Theta))
total_score <- tscore[findInterval(theta, tscore[, 1]), 2]
lower_ci <- theta - error
upper_ci <- theta + error
lower_score <- tscore[findInterval(round(lower_ci, digits = 2), tscore[, 1]), 2]
upper_score <- tscore[findInterval(round(upper_ci, digits = 2), tscore[, 1]), 2]
list(theta = theta, total_score = total_score, lower_score = lower_score, upper_score = upper_score)
}
#Training Model on training Data
# Apply the function to SAPS training data
saps_trainResults <- lapply(saps_train_responses, calculate_scores, coef=sapsCoef, resultGRM=sapsResultGRM)
#Training Model on training Data
# Apply the function to SAPS training data
saps_trainResults <- lapply(saps_train_responses, calculate_scores, coef=sapsCoef, resultGRM=sapsResultGRM)
View(sans_train_responses)
View(sans_train_responses)
print(dim(saps_train_responses))
# Load required libraries
library(stats4)
library(lattice)
library(mirt)
library(shiny)
library(readxl)
library(catR)
library(writexl)
library(shinyBS)
library(shinyjs)
library(shinydashboard)
library(DT)
library(ggplot2)
# Load data
questions <- read.csv("Questions.csv")
questions2 <- read.csv("Questions2.csv")
load("sapsCoef.Rdata")
load("sapsResultGRM.Rdata")
load("sansCoef.Rdata")
load("sansResultGRM.Rdata")
set.seed(123) # for reproducibility
# Assuming responses are in a data frame format
responses <- read.csv("responses.csv")  # Placeholder for actual data file
responses2 <- read.csv("responses2.csv")  # Placeholder for actual data file
# Split the data
train_index <- sample(seq_len(nrow(responses)), size = 0.8 * nrow(responses))
train_data <- responses[train_index, ]
test_data <- responses[-train_index, ]
train_index2 <- sample(seq_len(nrow(responses2)), size = 0.8 * nrow(responses2))
# Assuming responses are in a data frame format
responses <- read.csv("SAPS_answer.csv")
responses2 <- read.csv("SANS_answer.csv")
# Split the data
train_index <- sample(seq_len(nrow(responses)), size = 0.8 * nrow(responses))
train_data <- responses[train_index, ]
test_data <- responses[-train_index, ]
train_index2 <- sample(seq_len(nrow(responses2)), size = 0.8 * nrow(responses2))
train_data2 <- responses2[train_index2, ]
test_data2 <- responses2[-train_index2, ]
estimate_scores <- function(coef, data, model = "GRM") {
x <- as.numeric(data)
theta <- thetaEst(coef, x, model = model, range = c(-6, 6), method = "BM")
theta
}
# Estimate scores for SAPS
train_scores <- apply(train_data, 1, estimate_scores, coef = sapsCoef)
# Step 1: Data Splitting
set.seed(123)
trainIndex <- createDataPartition(questions$score, p = .8,
list = FALSE,
times = 1)
questionsTrain <- questions[ trainIndex,]
questionsTest  <- questions[-trainIndex,]
trainIndex2 <- createDataPartition(questions2$score, p = .8,
list = FALSE,
times = 1)
questionsTrain2 <- questions2[ trainIndex2,]
questionsTest2  <- questions2[-trainIndex2,]
library(caret)
trainIndex2 <- createDataPartition(questions2$score, p = .8,
list = FALSE,
times = 1)
View(saps_answers)
View(saps_answers)
View(sans_val_responses)
View(sapsResultGRM)
# Load required libraries
library(stats4)
library(lattice)
library(mirt)
library(shiny)
library(readxl)
library(catR)
library(writexl)
library(shinyBS)
library(shinyjs)
library(shinydashboard)
library(DT)
library(ggplot2)
library(caret)
# Load data
questions <- read.csv("Questions.csv")
questions2 <- read.csv("Questions2.csv")
load("sapsCoef.Rdata")
load("sapsResultGRM.Rdata")
load("sansCoef.Rdata")
load("sansResultGRM.Rdata")
# Step 1: Data Splitting
set.seed(123)
trainIndex <- sample(seq_len(nrow(questions)), size = 0.8 * nrow(questions))
questionsTrain <- questions[ trainIndex,]
questionsTest  <- questions[-trainIndex,]
trainIndex2 <- sample(seq_len(nrow(questions2)), size = 0.8 * nrow(questions2))
questionsTrain2 <- questions2[ trainIndex2,]
questionsTest2  <- questions2[-trainIndex2,]
# Step 2: Train the Model
modelSAPS <- mirt(questionsTrain[, 4:9], 1, itemtype = 'graded')
modelSANS <- mirt(questionsTrain2[, 4:9], 1, itemtype = 'graded')
# Step 3: Validate the Model
predSAPS <- fscores(modelSAPS, method = "ML", response.pattern = questionsTest[, 4:9])
predSANS <- fscores(modelSANS, method = "ML", response.pattern = questionsTest2[, 4:9])
actualSAPS <- rowSums(questionsTest[, 4:9])
actualSANS <- rowSums(questionsTest2[, 4:9])
# Correlation
correlation_SAPS <- cor(predSAPS, actualSAPS)
correlation_SANS <- cor(predSANS, actualSANS)
# Mean Absolute Error
mae_SAPS <- mean(abs(predSAPS - actualSAPS))
mae_SANS <- mean(abs(predSANS - actualSANS))
# Classification Accuracy
cutoff <- 37  # Example cutoff
predicted_class <- ifelse(predSAPS + predSANS > cutoff, 1, 0)
actual_class <- ifelse(actualSAPS + actualSANS > cutoff, 1, 0)
# Load necessary data
questions <- read.csv("Questions.csv")
questions2 <- read.csv("Questions2.csv")
saps_answers <- read.csv("SAPS_answer.csv")
sans_answers <- read.csv("SANS_answer.csv")
load("sapsCoef.Rdata")
load("sapsResultGRM.Rdata")
load("sansCoef.Rdata")
load("sansResultGRM.Rdata")
# Step 1: Data Splitting
set.seed(123)
trainIndex <- sample(seq_len(nrow(saps_answers)), size = 0.8 * nrow(saps_answers))
sapsTrain <- saps_answers[trainIndex,]
sapsTest <- saps_answers[-trainIndex,]
trainIndex2 <- sample(seq_len(nrow(sans_answers)), size = 0.8 * nrow(sans_answers))
sansTrain <- sans_answers[trainIndex2,]
sansTest <- sans_answers[-trainIndex2,]
# Step 2: Check for Variability in Training Data
check_variability <- function(data) {
sapply(data, function(x) length(unique(x)))
}
variability_saps <- check_variability(sapsTrain)
sapsTrain <- sapsTrain[, which(variability_saps > 1)]
sapsTest <- sapsTest[, which(variability_saps > 1)]
variability_sans <- check_variability(sansTrain)
sansTrain <- sansTrain[, which(variability_sans > 1)]
sansTest <- sansTest[, which(variability_sans > 1)]
# Step 3: Train the Model
modelSAPS <- mirt(sapsTrain, 1, itemtype = 'graded')
modelSANS <- mirt(sansTrain, 1, itemtype = 'graded')
# Step 4: Validate the Model
predSAPS <- fscores(modelSAPS, method = "ML", response.pattern = sapsTest)
predSANS <- fscores(modelSANS, method = "ML", response.pattern = sansTest)
# Assuming the true scores are calculated somehow (you might need to adapt this)
# Here we are using the sum of the answers as a proxy for the actual score
actualSAPS <- rowSums(sapsTest)
actualSANS <- rowSums(sansTest)
# Calculate metrics
# Correlation
correlation_SAPS <- cor(predSAPS, actualSAPS)
correlation_SANS <- cor(predSANS, actualSANS)
# Mean Absolute Error
mae_SAPS <- mean(abs(predSAPS - actualSAPS))
mae_SANS <- mean(abs(predSANS - actualSANS))
# Classification Accuracy
cutoff <- 37  # Example cutoff
predicted_class <- ifelse(predSAPS + predSANS > cutoff, 1, 0)
actual_class <- ifelse(actualSAPS + actualSANS > cutoff, 1, 0)
accuracy <- mean(predicted_class == actual_class)
# Print results
cat("SAPS-SANS Model Validation Results:\n")
cat("Correlation (SAPS): ", correlation_SAPS, "\n")
cat("Correlation (SANS): ", correlation_SANS, "\n")
cat("Mean Absolute Error (SAPS): ", mae_SAPS, "\n")
cat("Mean Absolute Error (SANS): ", mae_SANS, "\n")
cat("Classification Accuracy: ", accuracy, "\n")
View(sapsCoef)
View(sapsCoef)
